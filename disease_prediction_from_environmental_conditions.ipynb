{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7tUoUduU3it"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "738jgjwsVEKr"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('expandedd_dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_XbjVxpVxc_"
      },
      "outputs": [],
      "source": [
        "# Encode categorical variables: 'location', 'month', and 'disease'\n",
        "label_encoder_location = LabelEncoder()\n",
        "label_encoder_month = LabelEncoder()\n",
        "label_encoder_disease = LabelEncoder()\n",
        "\n",
        "df['location'] = label_encoder_location.fit_transform(df['location'])\n",
        "df['month'] = label_encoder_month.fit_transform(df['month'])\n",
        "df['disease'] = label_encoder_disease.fit_transform(df['disease'])\n",
        "\n",
        "# Feature Scaling: Scale only the numerical features\n",
        "numerical_features = ['total', 'preasure', 'rain', 'sun', 'humidity', 'mean_temp',\n",
        "                      'max_temp', 'min_temp', 'wind_gust', 'mean_wind_spd']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
        "\n",
        "# Step 3: Prepare the data for training\n",
        "\n",
        "# Define X (features) and y (target)\n",
        "X = df.drop(columns=['disease', 'ID'])  # Features\n",
        "y = df['disease']  # Target (disease)\n",
        "\n",
        "# Split the dataset into training and test sets (70% training, 30% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-RdA2hUVSib",
        "outputId": "b813644b-5c03-4f84-a63c-988991f17552"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [04:35:54] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Voting Classifier Accuracy: 24.67%\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       Asthma       0.17      0.21      0.19        43\n",
            "      Cholera       0.14      0.08      0.11        24\n",
            "    Dysentery       0.00      0.00      0.00        17\n",
            "     Dysentry       0.30      0.32      0.31        25\n",
            "  Guinea worm       0.17      0.13      0.15        15\n",
            "  Guinea_worm       0.00      0.00      0.00         0\n",
            "      Malaria       0.49      0.54      0.51        54\n",
            "Skin diseases       0.07      0.04      0.05        26\n",
            "Skin_diseases       0.23      0.29      0.26        24\n",
            "      Typhoid       0.19      0.25      0.21        52\n",
            " Yellow fever       0.30      0.15      0.20        20\n",
            " Yellow_fever       0.00      0.00      0.00         0\n",
            "\n",
            "     accuracy                           0.25       300\n",
            "    macro avg       0.17      0.17      0.17       300\n",
            " weighted avg       0.23      0.25      0.24       300\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 9  2  1  9  1  0  3  1  1 16  0  0]\n",
            " [ 3  2  1  1  2  0  6  1  2  5  1  0]\n",
            " [ 1  1  0  1  1  0  5  3  1  4  0  0]\n",
            " [ 8  2  0  8  0  1  0  0  2  4  0  0]\n",
            " [ 5  0  0  1  2  0  3  2  0  2  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 3  1  4  0  2  0 29  2  7  5  1  0]\n",
            " [ 8  0  2  3  0  0  3  1  0  6  3  0]\n",
            " [ 2  0  0  0  0  0  5  0  7 10  0  0]\n",
            " [11  4  0  4  2  0  2  4  9 13  2  1]\n",
            " [ 3  2  1  0  2  0  3  1  1  4  3  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Initialize individual models\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
        "\n",
        "# Create a voting classifier\n",
        "voting_clf = VotingClassifier(estimators=[\n",
        "    ('rf', rf_model),\n",
        "    ('lr', lr_model),\n",
        "    ('xgb', xgb_model)\n",
        "], voting='soft')\n",
        "\n",
        "# Train the voting classifier\n",
        "voting_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_voting = voting_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(f\"Voting Classifier Accuracy: {accuracy_score(y_test, y_pred_voting) * 100:.2f}%\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_voting, target_names=label_encoder_disease.classes_))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_voting))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BWi2XJYYi8j",
        "outputId": "097e2150-b8f7-4513-82ab-3908cd53f95b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1620 candidates, totalling 4860 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [05:53:40] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'lr__C': 100, 'rf__max_depth': 10, 'rf__n_estimators': 50, 'xgb__learning_rate': 0.01, 'xgb__max_depth': 3, 'xgb__n_estimators': 200}\n",
            "Voting Classifier Accuracy (Tuned): 26.00%\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       Asthma       0.11      0.12      0.11        43\n",
            "      Cholera       0.17      0.04      0.07        24\n",
            "    Dysentery       0.00      0.00      0.00        17\n",
            "     Dysentry       0.27      0.48      0.34        25\n",
            "  Guinea worm       0.29      0.13      0.18        15\n",
            "  Guinea_worm       0.00      0.00      0.00         0\n",
            "      Malaria       0.48      0.54      0.51        54\n",
            "Skin diseases       0.25      0.04      0.07        26\n",
            "Skin_diseases       0.20      0.25      0.22        24\n",
            "      Typhoid       0.22      0.40      0.29        52\n",
            " Yellow fever       0.25      0.05      0.08        20\n",
            " Yellow_fever       0.00      0.00      0.00         0\n",
            "\n",
            "     accuracy                           0.26       300\n",
            "    macro avg       0.19      0.17      0.16       300\n",
            " weighted avg       0.25      0.26      0.23       300\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 5  1  1 11  0  0  5  1  1 18  0  0]\n",
            " [ 4  1  0  4  2  0  3  0  3  6  1  0]\n",
            " [ 1  0  0  2  1  0  4  0  1  8  0  0]\n",
            " [ 6  0  0 12  0  1  0  0  0  6  0  0]\n",
            " [ 5  0  0  3  2  0  2  0  0  2  1  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 5  1  1  4  0  0 29  1  6  7  0  0]\n",
            " [ 8  0  1  3  0  0  5  1  0  7  1  0]\n",
            " [ 2  0  0  0  0  0  5  0  6 11  0  0]\n",
            " [ 8  2  0  5  1  0  3  1 10 21  0  1]\n",
            " [ 0  1  0  1  1  0  4  0  3  9  1  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grids for each model\n",
        "param_grid = {\n",
        "    'rf__n_estimators': [50, 100, 200],\n",
        "    'rf__max_depth': [None, 10, 20, 30],\n",
        "    'lr__C': [0.01, 0.1, 1, 10, 100],\n",
        "    'xgb__n_estimators': [50, 100, 200],\n",
        "    'xgb__learning_rate': [0.01, 0.1, 0.2],\n",
        "    'xgb__max_depth': [3, 6, 10]\n",
        "}\n",
        "\n",
        "# Initialize Voting Classifier\n",
        "voting_clf = VotingClassifier(estimators=[\n",
        "    ('rf', rf_model),\n",
        "    ('lr', lr_model),\n",
        "    ('xgb', xgb_model)\n",
        "], voting='soft')\n",
        "\n",
        "# Perform GridSearchCV for hyperparameter tuning\n",
        "grid_search = GridSearchCV(estimator=voting_clf, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=2)\n",
        "\n",
        "# Fit the model using GridSearchCV\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters from grid search\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Make predictions using the best estimator\n",
        "y_pred_voting = grid_search.best_estimator_.predict(X_test)\n",
        "\n",
        "# Evaluate the tuned model\n",
        "print(f\"Voting Classifier Accuracy (Tuned): {accuracy_score(y_test, y_pred_voting) * 100:.2f}%\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_voting, target_names=label_encoder_disease.classes_))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_voting))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6n3YNogYX4C7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Initialize the Random Forest model\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Step 3: Initialize GridSearchCV with 5-fold cross-validation\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid,\n",
        "                           cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
        "\n",
        "# Step 4: Fit the GridSearchCV on the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Print the best parameters and best score found by GridSearchCV\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Accuracy Score:\", grid_search.best_score_)\n",
        "\n",
        "# Step 6: Make predictions using the best model found by GridSearchCV\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "y_pred = best_rf_model.predict(X_test)\n",
        "\n",
        "# Step 7: Evaluate the tuned model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Tuned Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Get the unique classes in the test set\n",
        "unique_classes_test = np.unique(y_test)\n",
        "\n",
        "# Step 8: Generate the classification report dynamically\n",
        "# Fetch the class labels corresponding to the unique classes in y_test\n",
        "class_labels = label_encoder_disease.inverse_transform(unique_classes_test)\n",
        "\n",
        "print(\"\\nTuned Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=class_labels))\n",
        "\n",
        "# Optional: Confusion Matrix\n",
        "print(\"\\nTuned Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred, labels=unique_classes_test))"
      ],
      "metadata": {
        "id": "HTAb98RxaM2-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}